To showcase the need for datasets such as the one presented in this publication, we now shortly discuss some recent
approaches that apply machine learning methods to classification and regression tasks for powder diffractograms. \\

Using simulated diffractograms based on structures from the ICSD, Lee {\it et al.} trained a deep convolutional neural network (CNN) that is able to classify occurring phases in diffractograms of a specific compound pool \cite{Lee2020}. They furthermore developed models based on fully convolutional neural networks and transformer encoders that predict the crystal system, the spacegroup, and other structural properties, such as the band gap \cite{Lee2022}. With their best model for the crystal system prediction on ICSD structures, they achieved a test accuracy of \SI{92.2}{\percent}. Park {\it et al.} reached a test accuracy of roughly \SI{81}{\percent} for a CNN, which classifies space groups of simulated single-phase diffractograms \cite{Park2017}. \\

A regression analysis on lattice parameters within a broader framework encompassing all material classes was conducted by Chitturi {\it et al} \cite{Chitturi2021}. They developed a distinct CNN for each crystal system, utilizing a merged dataset from both the ICSD and the Cambridge Structural Database, and managed to achieve a mean absolute percentage error of about \SI{10}{\percent} for the lattice lengths, although they encountered difficulties in accurately predicting angles.
Zhang {\it et al.} introduce a convolutional self-attention neural network trained on simulated patterns to classify crystal types \cite{zhang2024crystallographic}. Their model was tested on 23,073 unary, binary, and ternary inorganic crystal structures sourced from the COD. The study observed a noticeable performance drop when the pre-trained model was applied to real experimental patterns, as opposed to simulated data. However, their recent work \cite{cao2024simxrd} proposes using convolutional peak descriptors that consider the detector's geometry, which reduces the performance gap in their benchmark tests.\\

The option of training purely on experimental diffractograms unfortunately is infeasible because of the limited availability of labeled experimental diffractograms, but Salgado {\it et al.} \cite{Salgado2023} showed that adding a fraction of experimental patterns to a simulated training dataset improves the performance on unseen experimental patterns. They used \SI{50}{\percent} of the experimental patterns contained in the RRUFF database and added those to their large simulated training set. Then they tested their model's performance on the other half of the RRUFF database and achieved a performance increase in the 230-way spacegroup classification accuracy of \num{11} percentage points compared to the same model only trained on simulated patterns. \\

Schuetzke {\it et al.} trained a classifier to classify if a diffractogram stems from an amorphous, single-phase, or multi-phase sample \cite{Schuetzke2024}. Due to the lack of experimental pXRDs, they built a pipeline to augment simulated diffractograms of a reference structure by, among other things, slightly varying the underlying crystal lattice. For spinel structures, they reported an accuracy of \SI{100}{\percent} but they also proved that their approach can be transferred to other datasets.\\

In our 2023 paper, we developed an approach to generate synthetic crystal structures and their corresponding pXRD patterns on the fly during the training process \cite{Schopmans2023}. This approach defeats the issue of
a limited dataset size, which limits the depth of neural networks that can be trained. However, the accuracy dropped substantially when we applied our space group classification model to experimental patterns from the RRUFF database. Augmenting our simulated patterns with background, noise, and impurities helps to bring simulated diffractograms closer to experimental ones, making models trained on them more performant on experimental diffractograms. However, this augmentation process could be improved by incorporating background and noise statistics from a broader experimental pXRD database, such as the one presented in this publication.\\

It becomes apparent that the more general the task is, the more challenging the transfer to experimental data becomes. For example, the space group classification task across all material systems is very general. Therefore, transferring it to the application on experimental diffraction patterns is difficult. \cite{Schopmans2023, Lee2022, Vecsei2018} On the other hand, there are some successful approaches that also work well on experimental data, but those are mostly methods that do phase determination in a limited compound space, making the task less complex. \cite{Schuetzke2024, Lee2020}\\

The ultimate goal of ML efforts is to make pXRD data identification practical for experimental use, automating structure prediction. However, the current volume of experimental pXRD patterns is insufficient to effectively train ML models, highlighting an urgent need for a comprehensive experimental pXRD database. Two key approaches are essential to address this. First, developing more sophisticated simulation methods to better approximate experimental patterns\cite{cao2024simxrd} by using statistics from experimental diffractograms. Second, creating an experimental database that enables transfer learning to bridge the gap between simulated and real-world data. For both of these steps, the development of opXRD is particularly significant, as it will provide a comprehensive experimental benchmark for the community, allowing fair comparison of baseline models and accurate evaluation of their applicability in real experimental situations.