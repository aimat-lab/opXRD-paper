\subsubsection*{Review of machine learning-based pXRD analysis}
To showcase the need for datasets such as the one presented in this publication, we now discuss some recent approaches that apply machine learning methods to classification and regression tasks for powder diffractograms.

In 2020, Lee {\it et al.} trained a deep convolutional neural network (CNN) using simulated diffractograms based on structures from the ICSD, which is able to classify occurring phases in diffractograms of a specific compound pool \cite{Lee2020}. In 2022, they furthermore developed models based on fully convolutional neural networks and transformer encoders that predict the crystal system, the spacegroup, and other structural properties, such as the band gap \cite{Lee2022}. With their best model for the crystal system prediction on ICSD structures, they achieved a test accuracy of \SI{92.2}{\percent}. In 2017, Park {\it et al.} reached a test accuracy of roughly \SI{81}{\percent} for a CNN, which classifies space groups of simulated single-phase diffractograms \cite{Park2017}.

A regression analysis on lattice parameters within a broader framework encompassing all material classes was conducted by Chitturi {\it et al} \cite{Chitturi2021} in 2021. They developed a distinct CNN for each crystal system, utilizing a merged dataset from both the ICSD and the Cambridge Structural Database, and managed to achieve a mean absolute percentage error of about \SI{10}{\percent} for the lattice lengths, although they encountered difficulties in accurately predicting angles.
In 2024, Zhang {\it et al.} introduced a convolutional self-attention neural network trained on simulated patterns to classify crystal types \cite{zhang2024crystallographic}. Their model was tested on 23,073 unary, binary, and ternary inorganic crystal structures sourced from the COD. The study observed a noticeable performance drop when the pre-trained model was applied to real experimental patterns as opposed to simulated data. However, their recent work \cite{cao2024simxrd} proposes using convolutional peak descriptors that consider the detector's geometry, which reduces the performance gap in their benchmark tests.

Neural networks trained purely on experimental diffractograms can perform well when the range of samples is narrow and the data is collected only on a single machine \cite{Lee2023, hattrick-simpers2021}. However, in a more general setting with a wide range of investigated samples and employed diffractometers training neural networks purely on experimental diffractograms becomes infeasible. This is because of the limited availability of labeled experimental diffractograms relative to the scope of the task. However, in 2023, Salgado {\it et al.} \cite{Salgado2023} showed that adding a fraction of experimental patterns to a simulated training dataset improves the performance on unseen experimental patterns. They used \SI{50}{\percent} of the experimental patterns contained in the RRUFF database and added those to their large simulated training set. Then they tested their model's performance on the other half of the RRUFF database and achieved a performance increase in the 230-way spacegroup classification accuracy of \num{11} percentage points compared to the same model only trained on simulated patterns.

In 2024, Schuetzke {\it et al.} trained a classifier to classify if a diffractogram stems from an amorphous, single-phase, or multi-phase sample \cite{Schuetzke2024}. Due to the lack of experimental pXRDs, they built a pipeline to augment simulated diffractograms of a reference structure by, among other things, slightly varying the underlying crystal lattice. For spinel structures, they reported an accuracy of \SI{100}{\percent} but they also proved that their approach can be transferred to other datasets.

In 2023, Schopmans {\it et al.} presented an approach to generate synthetic crystal structures and their corresponding pXRD patterns on the fly during the training process \cite{Schopmans2023}. This approach defeats the issue of a limited dataset size, which limits the depth of neural networks that can be trained. However, the accuracy dropped substantially when we applied our space group classification model to experimental patterns from the RRUFF database. Augmenting our simulated patterns with background, noise, and impurities helps to bring simulated diffractograms closer to experimental ones, making models trained on them more performant on experimental diffractograms. However, this augmentation process could be improved by incorporating background and noise statistics from a broader experimental pXRD database, such as the one presented in this publication.

It becomes apparent that the more general the task is, the more challenging the transfer to experimental data becomes. For example, the space group classification task across all material systems is very general. Therefore, transferring it to the application on experimental diffraction patterns is difficult. \cite{Schopmans2023, Lee2022, Vecsei2018} On the other hand, there are some successful approaches that also work well on experimental data, but those are mostly methods that do phase determination in a limited compound space, making the task less complex \cite{Schuetzke2024, Lee2020}. 

The current volume of experimental pXRD patterns is insufficient to effectively train ML models, highlighting an urgent need for a comprehensive experimental pXRD database. The most advanced ML models currently are trained on approximately $10^5 - 10^6$ simulated diffractograms \cite{Salgado2023, Schopmans2023}. This is, to the best of our knowledge, two orders of magnitude larger than the largest currently curated experimental dataset, the PDF-5+ with approximately $2\cdot 10^4$ experimental patterns. It is even one order of magnitude larger than the approximately $10^5$ unlabeled diffractograms in the initial version of the opXRD dataset we present here.

To make ML-based pXRD data identification practical for experimental use and automate structure prediction despite lacking experimental training data two key approaches are essential. First, developing more sophisticated simulation methods to better approximate experimental patterns\cite{cao2024simxrd} by using statistics from experimental diffractograms. Second, creating an experimental database that enables transfer learning to bridge the gap between simulated and real-world data. For both of these steps, the development of opXRD is particularly significant, as it will provide a comprehensive experimental benchmark for the community, allowing fair comparison of baseline models and accurate evaluation of their applicability in real experimental situations.